{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports: libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../../dataset/KAG_energydata_complete.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define split ratio and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "split_index = int(len(data) * split_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (15788, 28)\n",
      "Test data shape: (3947, 28)\n"
     ]
    }
   ],
   "source": [
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n",
    "\n",
    "print(f'Training data shape: {train_data.shape}')\n",
    "print(f'Test data shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose feature to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'Appliances'\n",
    "train_series = train_data[column_name]\n",
    "test_series = test_data[column_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible values for trend and seasonal components\n",
    "trend_options = ['add', 'mul', None]\n",
    "seasonal_options = ['add', 'mul', None]\n",
    "seasonal_periods = 7\n",
    "\n",
    "# Create all combinations of trend and seasonality\n",
    "combinations = list(itertools.product(trend_options, seasonal_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_aic = float('inf')\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trend, seasonal in combinations:\n",
    "    if trend is None and seasonal is None:\n",
    "        continue  # Skip the combination where both trend and seasonal are None\n",
    "\n",
    "    try:\n",
    "        model = sm.tsa.ExponentialSmoothing(train_series, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods)\n",
    "        model_fit = model.fit()\n",
    "        aic = model_fit.aic\n",
    "\n",
    "        print(f\"Trend: {trend}, Seasonal: {seasonal}, AIC: {aic}\")\n",
    "\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_model = model_fit\n",
    "            best_params = (trend, seasonal)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trend: {trend}, Seasonal: {seasonal} - Model failed with error: {e}\")\n",
    "\n",
    "print(f\"Best Model: Trend: {best_params[0]}, Seasonal: {best_params[1]}, AIC: {best_aic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "actuals = []\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_series), batch_size):\n",
    "    end_index = i + batch_size if i + batch_size < len(test_series) else len(test_series)\n",
    "    train_window = np.concatenate([train_series, test_series[:i]])\n",
    "    \n",
    "    try:\n",
    "        # Fit the ETS model\n",
    "        model = sm.tsa.ExponentialSmoothing(train_window, trend=best_params[0], seasonal=best_params[1], seasonal_periods=seasonal_periods)\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        # Forecast\n",
    "        forecast = model_fit.forecast(steps=end_index - i)\n",
    "        predictions.extend(forecast)\n",
    "        actuals.extend(test_series[i:end_index])\n",
    "    except Exception as e:\n",
    "        print(f\"Model failed at batch {i} with error: {e}\")\n",
    "\n",
    "# Convert predictions to pandas Series for evaluation\n",
    "predictions = pd.Series(predictions, index=test_series.index[:len(predictions)])\n",
    "actuals = pd.Series(actuals, index=test_series.index[:len(actuals)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "ets_mae = mean_absolute_error(actuals, predictions)\n",
    "ets_mse = mean_squared_error(actuals, predictions)\n",
    "ets_rmse = np.sqrt(ets_mse)\n",
    "ets_r2 = r2_score(actuals, predictions)\n",
    "\n",
    "print('Mean Absolute Error (MAE):', ets_mae)\n",
    "print('Mean Squared Error (MSE):', ets_mse)\n",
    "print('Root Mean Squared Error (RMSE):', ets_rmse)\n",
    "print('R-squared:', ets_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(actuals.index, actuals, label='Actual')\n",
    "plt.plot(predictions.index, predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the residuals\n",
    "residuals = actuals.values - predictions.values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(actuals.index, residuals, label='Residuals')\n",
    "plt.title('Residuals Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
